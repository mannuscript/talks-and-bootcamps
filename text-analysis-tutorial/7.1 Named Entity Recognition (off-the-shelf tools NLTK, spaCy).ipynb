{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (off-the-shelf tools NLTK, spaCy)\n",
    "\n",
    "Named Entity Recognition has become such a common task that many available tools provide NER out of the box. In this tutorial, we use NLTK and spaCy to perform this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "\n",
    "from nltk import sent_tokenize, sent_tokenize, word_tokenize, pos_tag, ne_chunk\n",
    "from nltk.tree import Tree\n",
    "\n",
    "from newspaper import Article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need the English model for spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a document\n",
    "\n",
    "For this tutorial, we use news articles as documents using the `newspaper` package to make it easy for us; see the \"Data Collection\" tutorial for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.straitstimes.com/asia/east-asia/now-its-japans-turn-to-brace-for-a-monster-storm-as-typhoon-lan-nears'\n",
    "url = 'http://www.straitstimes.com/singapore/ammonia-leak-in-food-factory-at-fishery-port-road-3-taken-to-hospital'\n",
    "#url = 'http://www.straitstimes.com/singapore/police-car-mounts-divider-in-accident-in-kampong-bahru-road-no-injuries'\n",
    "\n",
    "article = Article(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The methods `download()` and `parse()` fetch and process the current article. For the rest of this tutorial, we only consider the title and the main content (text) of an article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.download()\n",
    "article.parse()\n",
    "\n",
    "title = article.title\n",
    "text = article.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition with NLTK\n",
    "\n",
    "We first show how NLTK performs NLTK with a simple example sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sentence = \"Straits Times interviewed PM Lee last week in Japan.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For preprocessing we need to tokenize and POS-tag the sentence, since POS tags a required for the NER extractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize sentence\n",
    "token_list = word_tokenize(example_sentence)\n",
    "# POS tag token list\n",
    "token_pos_list = pos_tag(token_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK proivdes a method `ne_chunk` (ne = named entity) which labels words or phrases as named entities. The result is a token tree, an internal representation used in NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Straits/NNS\n",
      "  (PERSON Times/NNP)\n",
      "  interviewed/VBD\n",
      "  (ORGANIZATION PM/NNP Lee/NNP)\n",
      "  last/JJ\n",
      "  week/NN\n",
      "  in/IN\n",
      "  (GPE Japan/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "# Perform named entity recogniztion through chunking\n",
    "ne_chunk_tree = ne_chunk(token_pos_list, binary=False)\n",
    "\n",
    "print(ne_chunk_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following auxiliary method goes trough the tree and extract the named entities and put them with their label into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_named_entities(tree):\n",
    "    chunk_list = []\n",
    "    for i in tree:\n",
    "        if type(i) == Tree:\n",
    "            label = i.label()\n",
    "            name = \" \".join([token for token, pos in i.leaves()])\n",
    "            chunk_list.append((name, label))\n",
    "        else:\n",
    "            continue\n",
    "    return chunk_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Times', 'PERSON'), ('PM Lee', 'ORGANIZATION'), ('Japan', 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "print(extract_named_entities(ne_chunk_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can repate this steps with the news article. First we need to tokenize the document into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence, we perform the required steps as shown above:\n",
    "\n",
    "* tokenize sentice into words/tokens\n",
    "* POS-tag token list\n",
    "* Perform NER using `ne_chunk()`\n",
    "* Extract found named entities and put them into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- SINGAPORE (GPE)\n",
      "-- Jurong (GPE)\n",
      "-- Singapore Civil Defence Force (ORGANIZATION)\n",
      "-- SCDF (ORGANIZATION)\n",
      "-- Fishery Port Road (PERSON)\n",
      "-- Ben Foods (PERSON)\n",
      "-- SCDF (ORGANIZATION)\n",
      "-- SCDF (ORGANIZATION)\n",
      "-- SCDF (ORGANIZATION)\n",
      "-- Ng Teng Fong (PERSON)\n",
      "-- SCDF (ORGANIZATION)\n",
      "-- Salim Anwar (PERSON)\n",
      "-- NCS Cold Stores (ORGANIZATION)\n",
      "-- Ben Foods (PERSON)\n",
      "-- Straits Times (ORGANIZATION)\n",
      "-- Fauzan Tahir (PERSON)\n",
      "-- Ben Foods (PERSON)\n",
      "-- ST (ORGANIZATION)\n",
      "-- SCDF (ORGANIZATION)\n",
      "-- SCDF (ORGANIZATION)\n",
      "-- SCDF (ORGANIZATION)\n",
      "-- HazMat (ORGANIZATION)\n",
      "-- Hazardous (ORGANIZATION)\n",
      "-- HazMat Specialists (ORGANIZATION)\n",
      "-- SCDF (ORGANIZATION)\n",
      "-- SCDF (ORGANIZATION)\n",
      "-- SCDF (ORGANIZATION)\n",
      "-- SCDF (ORGANIZATION)\n",
      "-- Ben Foods (PERSON)\n",
      "-- Kallang Way (PERSON)\n",
      "-- Pioneer (GPE)\n"
     ]
    }
   ],
   "source": [
    "for sent in sentences:\n",
    "    # Tokenize sentence\n",
    "    token_list = word_tokenize(sent)\n",
    "    # POS tag token list\n",
    "    token_pos_list = pos_tag(token_list)\n",
    "    # Perform named entity recogniztion through chunking\n",
    "    ne_chunk_tree = ne_chunk(token_pos_list, binary=False)\n",
    "    # Extract the named entities from tree into a simple list\n",
    "    named_entities_list = extract_named_entities(ne_chunk_tree)\n",
    "    # Print found named entities\n",
    "    for ne in named_entities_list:\n",
    "        print(\"-- {} ({})\".format(ne[0], ne[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition with spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When spaCy analyzes a document, it performs a whole series steps including tokenizing, POS tagging, lemmatization and even named entity recognition. That means, after performing the following command, the `doc` object already contains the intormation about found named entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The auxiliary method `show_named_entities()` simply prints all found named entities in a nice layout. The only additional - an optional - parameter is `valid_labels` that allows to specify a list of named entity types. For example, we can simply print all persons by setting `valid_labels=['person']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_named_entities(doc, valid_labels=None):\n",
    "    print('{:35} {:25} {:6} {:6}'.format(\"NAME\", \"LABEL\", \"START\", \"END\"))\n",
    "    for e in doc.ents:\n",
    "        label = e.label_.lower()\n",
    "        if valid_labels is not None:\n",
    "            if label not in valid_labels:\n",
    "                continue\n",
    "        # Print name, label, start and end (in a nice way)\n",
    "        print('{:35} {:25} {:5} {:5}'.format(e.text, label, e.start_char, e.end_char))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the found named entities for the current document. You can filter the list by specifying a list of valid labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                LABEL                     START  END   \n",
      "Jurong                              gpe                          81    87\n",
      "Friday                              date                         91    97\n",
      "Jan                                 person                       99   102\n",
      "The Singapore Civil Defence Force   org                         109   142\n",
      "SCDF                                org                         144   148\n",
      "Facebook                            gpe                         160   168\n",
      "1                                   cardinal                    231   232\n",
      "Fishery Port Road                   fac                         234   251\n",
      "about 11.40am.                      percent                     256   270\n",
      "Ben Foods                           person                      292   301\n",
      "first                               ordinal                     479   484\n",
      "SCDF                                org                         570   574\n",
      "SCDF                                org                         592   596\n",
      "SCDF                                org                         599   603\n",
      "three                               cardinal                    619   624\n",
      "Ng Teng Fong                        person                      684   696\n",
      "late afternoon                      time                        853   867\n",
      "SCDF                                org                         934   938\n",
      "four                                cardinal                    996  1000\n",
      "Salim Anwar                         person                     1006  1017\n",
      "68-year-old                         date                       1021  1032\n",
      "NCS Cold Stores                     org                        1071  1086\n",
      "Ben Foods                           person                     1113  1122\n",
      "The Straits Times                   org                        1129  1146\n",
      "8.30am                              cardinal                   1231  1237\n",
      "about 10.30am                       cardinal                   1244  1257\n",
      "Fauzan Tahir                        person                     1514  1526\n",
      "30                                  date                       1528  1530\n",
      "Ben Foods                           person                     1554  1563\n",
      "second                              ordinal                    1594  1600\n",
      "1                                   cardinal                   1764  1765\n",
      "3.15pm                              cardinal                   1784  1790\n",
      "3.45pm                              cardinal                   1907  1913\n",
      "SCDF                                org                        1915  1919\n",
      "SCDF                                org                        2014  2018\n",
      "SCDF                                org                        2052  2056\n",
      "HazMat (                            loc                        2059  2067\n",
      "The HazMat Specialists              org                        2211  2233\n",
      "9.05pm                              cardinal                   2386  2392\n",
      "SCDF                                org                        2394  2398\n",
      "SCDF                                org                        2621  2625\n",
      "the last three hours                date                       2888  2908\n",
      "SCDF                                org                        2910  2914\n",
      "three                               cardinal                   2933  2938\n",
      "About 100                           cardinal                   3153  3162\n",
      "SCDF                                org                        3213  3217\n",
      "Ben Foods                           person                     3292  3301\n",
      "July last year                      date                       3328  3342\n",
      "11                                  cardinal                   3344  3346\n",
      "Kallang Way                         gpe                        3449  3460\n",
      "September 2016                      date                       3466  3480\n",
      "seven                               cardinal                   3482  3487\n",
      "Pioneer                             org                        3579  3586\n"
     ]
    }
   ],
   "source": [
    "show_named_entities(doc)\n",
    "#show_named_entities(doc, valid_labels=['gpe', 'loc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of entitiy types supported by spaCy\n",
    "\n",
    "![title](images/ner-spacy-entity-labels.png \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
